# -*- coding: utf-8 -*-
"""TelecomX-Part1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UoX1W11kyaD6XhfkWa9tgEH1z6tKiH32

#Extracion de Datos
"""

import pandas as pd
import requests

# URL del archivo JSON en GitHub sin la interfaz web
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/main/TelecomX_Data.json"

# Obtener los datos desde la URL
response = requests.get(url)
data_json = response.json()

# Convertir a DataFrame
df = pd.DataFrame(data_json)

df

"""##Conoce el COnjunto de **Datos**"""

df.info()

df.dtypes

"""##Nos damos cuenta que esto es un diccionario con diccionarios mas pequeños entonces procedemos a normalizar

##Normalizando los datos
"""

df_custommer= pd.json_normalize(df['customer'])
df_custommer

df_phone= pd.json_normalize(df['phone'])
df_phone

df_internet= pd.json_normalize(df['internet'])
df_internet

df_account= pd.json_normalize(df['account'])
df_account

"""##Normalizacion final"""

df_account= pd.json_normalize(df['account'])
df_internet= pd.json_normalize(df['internet'])
df_phone= pd.json_normalize(df['phone'])
df_custommer= pd.json_normalize(df['customer'])
df_initial=pd.concat([df['customerID'],df['Churn']],axis=1)


df_final=pd.concat([df_initial,df_custommer,df_phone,df_internet,df_account],axis=1)
df_final

"""#Transformacion de los Datos"""

df_account= pd.json_normalize(df['account'])
df_internet= pd.json_normalize(df['internet'])
df_phone= pd.json_normalize(df['phone'])
df_custommer= pd.json_normalize(df['customer'])
df_initial=pd.concat([df['customerID'],df['Churn']],axis=1)


df_final=pd.concat([df_initial,df_custommer,df_phone,df_internet,df_account],axis=1)

"""### Recuento de valores nulos por columna / Valores ausentes (Missing values)


"""

# Recuento de valores nulos por columna
df_final.isnull().sum()

# Ver filas con nulos
df_final[df_final.isnull().any(axis=1)]

df_final.isnull().sum()

"""## Duplicados por **customerID**"""

# Duplicados por customerID
duplicados = df_final.duplicated(subset='customerID')
print(f"Duplicados encontrados: {duplicados.sum()}")

# Si quieres verlos
df_final[duplicados]

"""##Inconsistencias categóricas"""

print(df_final['PaymentMethod'].unique())
print(df_final['Contract'].unique())

df_final['PaymentMethod'] = df_final['PaymentMethod'].str.lower().str.strip()
df_final

"""##Formato de Fecha"""

df_final['fecha'] = pd.to_datetime(df_final['fecha']).dt.normalize()

#no hay fecha, entonces por tanto no detecta

"""##Datos Inesperados"""

df_final.dtypes

df_final

"""##Manejo de Inconsistencias"""

# Columnas con texto que puede tener variaciones
cols_texto = ['PaymentMethod', 'Contract', 'gender', 'InternetService', 'StreamingTV', 'StreamingMovies']

for col in cols_texto:
    df_final[col] = df_final[col].str.lower().str.strip()

df_final

"""##Busqueda de valores sospechosos (Startswith, contains)"""

df_final[df_final['InternetService'].str.contains('fiber', case=False, na=False)]
df_final[df_final['InternetService'].str.startswith('dsl', na=False)]


df_final

"""##Sustitucion de valores no informativos: n/a o unknown, o spcae null"""

df_final.replace(['n/a', 'unknown', ''], pd.NA, inplace=True)
df_final

"""##Limpieza especifica numerica"""

df_final['Charges.Monthly'] = df_final['Charges.Monthly'].astype(str).str.replace('[^0-9.]', '', regex=True)
df_final['Charges.Monthly'] = pd.to_numeric(df_final['Charges.Monthly'], errors='coerce')

df_final

"""##Validacion final"""

for col in cols_texto:
    print(f"{col}: {df_final[col].unique()}")

"""##Columna de cuentas diarias"""

#Partimos de la columna "Charges.Monthly" y asumimos que un mes promedio tiene 30 días:
df_final['Cuentas_Diarias'] = df_final['Charges.Monthly'] / 30  # promedio del año

df_final[['Charges.Monthly', 'Cuentas_Diarias']]

"""##Estandarización y transformación de datos (opcional)

###Conversión de valores "Sí/No" a binarios Yes = 1, No =0
"""

cols_binarias = ['Churn','Partner', 'Dependents', 'PhoneService', 'PaperlessBilling',
                 'StreamingTV', 'StreamingMovies', 'OnlineBackup',
                 'DeviceProtection', 'TechSupport', 'MultipleLines']

for col in cols_binarias:
    df_final[col] = df_final[col].replace({'yes': 1, 'no': 0,'Yes':1,'No':0,'No phone service':0, 'No internet service':0,'no internet service':0})

df_final

"""###Validacion rapida de transformacion"""

df_final.head(30)

"""#Carga y Analisis

## Análisis Descriptivo con describe()
"""

df_final.describe()

"""##Distribución de evasión

###Conteo de valores
"""

#"Churn" ya en formato binario (1 = evasión, 0 = permanencia) nos facilita muchísimo tanto la visualización como el modelado.

df_final['Churn'].value_counts()

labels = ['Permanecen', 'Evaden']
sizes = df_final['Churn'].value_counts()
colors = ['lightgreen', 'salmon']

plt.figure(figsize=(5,5))
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)
plt.title('Proporción de Evasión de Clientes')
plt.axis('equal')
plt.show()

"""##Recuento de evasión por variables categóricas

###Variables Categoricas de Interes
"""

variables_categoricas = ['gender', 'Contract', 'PaymentMethod', 'InternetService']

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
sns.barplot(x='Contract', y='Churn', data=df_final, estimator=lambda x: sum(x)/len(x), palette='pastel')
plt.title('Tasa de Evasión según Tipo de Contrato')
plt.ylabel('Proporción de Churn (1 = evasión)')
plt.xlabel('Tipo de Contrato')
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

#🔍 Este gráfico muestra el porcentaje de clientes que evaden por categoría:

for var in variables_categoricas:
    plt.figure(figsize=(6,4))
    sns.barplot(x=var, y='Churn', data=df_final, estimator=lambda x: sum(x)/len(x), palette='pastel')
    plt.title(f'Tasa de Evasión según {var}')
    plt.ylabel('Proporción de Churn')
    plt.xlabel(var)
    plt.xticks(rotation=15)
    plt.tight_layout()
    plt.show()

#Resumen

for var in variables_categoricas:
    tasa = df_final.groupby(var)['Churn'].mean().sort_values(ascending=False)
    print(f'\n{var} - Tasa de Churn:')
    print(tasa)

"""##Conteo de evasión por variables numéricas

###Boxplot de variables numéricas vs. evasión
"""

df_final.head(5)

import seaborn as sns
import matplotlib.pyplot as plt

precio_cols = ['Charges.Monthly', 'Charges.Total', 'Cuentas_Diarias']
df_final['Churn'] = pd.to_numeric(df_final['Churn'], errors='coerce')


for col in precio_cols:
    plt.figure(figsize=(6,4))
    sns.boxplot(hue='Churn', y=col, data=df_final, palette='pastel')
    plt.title(f'Distribución de {col} según Churn')
    plt.xlabel('Churn (0 = permanece, 1 = evasión)')
    plt.ylabel(col)
    plt.tight_layout()
    plt.show()

precio_cols = ['Charges.Monthly', 'Charges.Total', 'Cuentas_Diarias']

for col in precio_cols:
    df_final[col] = df_final[col].astype(str).str.replace('[^0-9.]', '', regex=True)
    df_final[col] = pd.to_numeric(df_final[col], errors='coerce')

import numpy as np

numericas = ['Charges.Monthly', 'Charges.Total', 'Cuentas_Diarias']
estadisticas = ['mean', 'median', 'std']

# Diccionario para guardar resultados
comparativo = {}

for col in numericas:
    comparativo[col] = {
        'Promedio (Evaden)': round(df_final[df_final['Churn'] == 1][col].mean(), 2),
        'Mediana (Evaden)': round(df_final[df_final['Churn'] == 1][col].median(), 2),
        'Desv.Std (Evaden)': round(df_final[df_final['Churn'] == 1][col].std(), 2),
        'Promedio (Permanecen)': round(df_final[df_final['Churn'] == 0][col].mean(), 2),
        'Mediana (Permanecen)': round(df_final[df_final['Churn'] == 0][col].median(), 2),
        'Desv.Std (Permanecen)': round(df_final[df_final['Churn'] == 0][col].std(), 2)
    }

import pandas as pd
pd.DataFrame(comparativo)

import seaborn as sns
import matplotlib.pyplot as plt

precio_cols = ['Charges.Monthly', 'Charges.Total', 'Cuentas_Diarias']
titles = ['Factura Mensual', 'Factura Total', 'Factura Diaria']

plt.figure(figsize=(16, 4))

for i, col in enumerate(precio_cols):
    plt.subplot(1, 3, i+1)
    sns.boxplot(x='Churn', y=col, data=df_final, palette='pastel')
    plt.title(f'Distribución de {titles[i]} según Churn')
    plt.xlabel('Churn (0 = Permanecen, 1 = Evaden)')
    plt.ylabel(titles[i])

plt.suptitle('Comparación de Costos entre Clientes que Evaden vs. Permanecen', fontsize=14, y=1.02)
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

precio_cols = ['Charges.Monthly', 'Charges.Total', 'Cuentas_Diarias']
titles = ['Factura Mensual', 'Factura Total', 'Factura Diaria']

plt.figure(figsize=(16, 4))

for i, col in enumerate(precio_cols):
    plt.subplot(1, 3, i+1)
    sns.violinplot(x='Churn', y=col, data=df_final, palette='pastel', inner='quartile')
    plt.title(f'Densidad de {titles[i]} según Churn')
    plt.xlabel('Churn (0 = Permanecen, 1 = Evaden)')
    plt.ylabel(titles[i])

plt.suptitle('Distribución Comparativa de Costos entre Clientes según Evasión', fontsize=14, y=1.05)
plt.tight_layout()
plt.show()



"""#Actividad Extra

###Paso 1: Calcular la matriz de correlación
Nos enfocamos en variables numéricas relevantes, incluyendo la columna binaria Churn:
"""

variables_interes = ['Churn', 'Charges.Monthly', 'Charges.Total', 'Cuentas_Diarias']

corr_matrix = df_final[variables_interes].corr()

"""###Visualizar con Heatmad"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", vmin=-1, vmax=1)
plt.title('Matriz de Correlación entre Variables Numéricas')
plt.tight_layout()
plt.show()

"""###Servicios contratados
Podemos crear una variable que sume cuántos servicios tiene el cliente. Por ejemplo:

"""

servicios = ['OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']
df_final['Servicios_Contratados'] = df_final[servicios].sum(axis=1)

"""###Y luego correlamos:"""

print(df_final[['Churn', 'Servicios_Contratados']].corr())

sns.boxplot(x='Churn', y='Servicios_Contratados', data=df_final, palette='pastel')
plt.title('Servicios Contratados vs. Evasión')
plt.show()

import plotly.express as px
import pandas as pd

# Asegurarse que churn esté como texto para etiquetas más claras
df_final['Churn_label'] = df_final['Churn'].replace({0: 'Permanecen', 1: 'Evaden'})

# Listado de variables numéricas a graficar
variables_numericas = ['Charges.Monthly', 'Charges.Total', 'Cuentas_Diarias']

for var in variables_numericas:
    fig = px.box(df_final, x='Churn_label', y=var, color='Churn_label',
                 title=f'Distribución de {var} según Evasión',
                 labels={'Churn_label': 'Churn', var: var},
                 color_discrete_map={'Permanecen': 'lightgreen', 'Evaden': 'salmon'})

    fig.update_layout(showlegend=False)
    fig.show()



"""#Informe Final Challenge Part 1

## 📘 Informe Final del Análisis de Evasión de Clientes (Churn)

---

## 🔹 Introducción

Este análisis busca entender los factores detrás del abandono de clientes (churn) en un servicio de telecomunicaciones. El objetivo principal es identificar patrones de comportamiento que expliquen la cancelación del servicio, y con ello desarrollar estrategias para retener clientes, optimizar recursos y mejorar la experiencia ofrecida.

---

## 🔹 Limpieza y Tratamiento de Datos

- Se partió de un archivo `.json` dividido en múltiples diccionarios: `customer`, `account`, `phone`, `internet`, `Churn`.
- Se aplicó la normalización con `pd.json_normalize()` y luego se consolidó todo en un solo `DataFrame` llamado `df_final`.
- Se identificaron y corrigieron incoherencias como valores nulos, duplicados, texto sucio o formatos incorrectos.
- Se estandarizaron respuestas binarias ("yes"/"no") a formato numérico (1/0), y se crearon nuevas métricas como:
  - `Cuentas_Diarias` → estimación de gasto diario
- También se renombraron columnas para facilitar su comprensión por equipos no técnicos (`Charges.Monthly` → `Factura_Mensual`, etc.).

---

## 🔹 Análisis Exploratorio de Datos

### 📌 Distribución de Evasión

- Los clientes que evaden representan una proporción significativa dentro del dataset.
- Los métodos de pago como cheque electrónico y los contratos mes a mes están más asociados con evasión.

### 📌 Variables Categóricas vs. Churn

- El tipo de contrato tiene una influencia clara: contratos de largo plazo tienen menor churn.
- No se observan diferencias destacables por género.

### 📌 Variables Numéricas vs. Churn

- Clientes que evaden suelen tener menos tiempo de permanencia (`Meses_Activos`) y menores gastos acumulados (`Factura_Total`).
- Su gasto mensual y diario suele ser más alto, lo que puede indicar percepción de bajo valor o frustración temprana.

### 📌 Correlaciones Relevantes

- `Churn` correlaciona negativamente con `Meses_Activos` y `Charges.Total`.
- `Cuentas_Diarias` tiene correlación positiva con churn: mayor gasto diario puede implicar mayor riesgo de cancelación.
- Se creó la variable `Servicios_Contratados`, demostrando que clientes con más servicios tienden a permanecer.

### 📌 Visualizaciones Interactivas

- Gráficos con Plotly permitieron explorar relaciones entre gasto, tiempo de contrato y evasión.
- Se utilizaron `violinplots`, `scatterplots` y `heatmaps` para detectar patrones densos y correlaciones ocultas.

---

## 🔹 Conclusiones e Insights

- La evasión se concentra en clientes con **menos meses activos**, **factura diaria más alta**, y que **no contratan múltiples servicios**.
- Los métodos de pago y el tipo de contrato son buenos indicadores de riesgo.
- El análisis sugiere que **retención y percepción de valor** son los ejes clave para frenar el churn.

---

## 🔹 Recomendaciones Estratégicas

- Promover **contratos de largo plazo** desde el onboarding del cliente.
- Crear paquetes con **servicios combinados** para aumentar fidelización.
- Implementar **alertas tempranas** para clientes con alta factura mensual y baja permanencia.
- Reconsiderar métodos de pago menos estables o propensos al abandono, como cheque electrónico.

---

✅ Este informe puede servir como base para crear un modelo predictivo de churn, identificar perfiles de riesgo y establecer acciones estratégicas orientadas a mejorar la retención. ¡El análisis está listo para impulsar decisiones de alto impacto! 🔎📈
"""

